{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##gDrive mount & setting dataset"
      ],
      "metadata": {
        "id": "-EjzXjpdp-5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWFgm_uHogqb",
        "outputId": "abfbcf0c-9610-4c70-e0ba-9ee83cb2d232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import"
      ],
      "metadata": {
        "id": "DTt7bE1gsRqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchsummary\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "from torch.utils.data.dataloader import Dataset , DataLoader"
      ],
      "metadata": {
        "id": "ArPo8XNPr-ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob"
      ],
      "metadata": {
        "id": "HRuzpmRrwMui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set device"
      ],
      "metadata": {
        "id": "HU-ii6CIxIZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-u363sRxH8U",
        "outputId": "5150408b-5676-4c6a-d5c4-7cfad8919165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare Dataset"
      ],
      "metadata": {
        "id": "Jgf71MWVxkBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/folder\""
      ],
      "metadata": {
        "id": "iRKabDzspmkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/folder\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IruGPWaGps14",
        "outputId": "9a2a1134-7f4f-402a-c3eb-a9a7147a15af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oxtCZVwq-oU",
        "outputId": "968c813d-0888-4056-f555-fcdb6bad4e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/hackertone/waveone_train.zip\" -d \"/content/folder/\"\n",
        "!unzip -qq \"/content/drive/MyDrive/hackertone/waveone_test.zip\" -d \"/content/folder/\"\n",
        "!unzip -qq \"/content/drive/MyDrive/hackertone/3_train.zip\" -d \"/content/folder/\""
      ],
      "metadata": {
        "id": "hrkMaydip8HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting data root"
      ],
      "metadata": {
        "id": "iewYSVEcvKmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = glob.glob('/content/folder/waveone_train/train/*/*') # (* : 모든 파일 선택), 모든 class에 있는 모든 사진 주소를 받아옴\n",
        "test_list = glob.glob('/content/folder/test/*/*') #test1폴더에 있는 모든 파일(사진)주소\n",
        "\n",
        "#print(train_img_list) #앞에 주석 제거하시면 어떻게 받아진건지 확인 할 수 있습니다.\n",
        "# print(test_img_list)"
      ],
      "metadata": {
        "id": "R8zWXlr0vGma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = pd.DataFrame(columns=['train_path', 'label']) #\n",
        "trainSet['train_path'] = train_list\n",
        "trainSet['label'] = trainSet['train_path'].apply(lambda x : str(x).split('/')[-2])\n",
        "\n",
        "for i in range(len(trainSet['label'])):\n",
        "    if trainSet['label'][i] == '1':\n",
        "        trainSet['label'][i] = np.array([1,0,0])\n",
        "    elif trainSet['label'][i] == '2':\n",
        "        trainSet['label'][i] = np.array([0,1,0])\n",
        "    elif trainSet['label'][i] == '3':\n",
        "        trainSet['label'][i] = np.array([0,0,1])\n",
        "\n",
        "\n",
        "print(trainSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywg0c2bFv5md",
        "outputId": "32bc1b69-f57f-4912-9ee2-70781eaec0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         train_path      label\n",
            "0    /content/folder/waveone_train/train/3/3_72.csv  [0, 0, 1]\n",
            "1    /content/folder/waveone_train/train/3/3_85.csv  [0, 0, 1]\n",
            "2    /content/folder/waveone_train/train/3/3_14.csv  [0, 0, 1]\n",
            "3    /content/folder/waveone_train/train/3/3_91.csv  [0, 0, 1]\n",
            "4    /content/folder/waveone_train/train/3/3_28.csv  [0, 0, 1]\n",
            "..                                              ...        ...\n",
            "295  /content/folder/waveone_train/train/2/2_96.csv  [0, 1, 0]\n",
            "296  /content/folder/waveone_train/train/2/2_99.csv  [0, 1, 0]\n",
            "297  /content/folder/waveone_train/train/2/2_56.csv  [0, 1, 0]\n",
            "298  /content/folder/waveone_train/train/2/2_61.csv  [0, 1, 0]\n",
            "299  /content/folder/waveone_train/train/2/2_39.csv  [0, 1, 0]\n",
            "\n",
            "[300 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testSet = pd.DataFrame(columns=['test_path', 'label']) #\n",
        "testSet['test_path'] = test_list\n",
        "testSet['label'] = testSet['test_path'].apply(lambda x : str(x).split('/')[-2])\n",
        "\n",
        "for i in range(len(testSet['label'])):\n",
        "    if testSet['label'][i] == '1':\n",
        "        testSet['label'][i] = np.array([1,0,0])\n",
        "    elif testSet['label'][i] == '2':\n",
        "        testSet['label'][i] = np.array([0,1,0])\n",
        "    elif testSet['label'][i] == '3':\n",
        "        testSet['label'][i] = np.array([0,0,1])\n",
        "\n",
        "\n",
        "print(testSet)"
      ],
      "metadata": {
        "id": "bZT6Ab-M-uik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a691ad-53f2-42c7-ce74-1adbb9d92b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           test_path      label\n",
            "0    /content/folder/test/3/3_72.csv  [0, 0, 1]\n",
            "1    /content/folder/test/3/3_85.csv  [0, 0, 1]\n",
            "2    /content/folder/test/3/3_14.csv  [0, 0, 1]\n",
            "3    /content/folder/test/3/3_91.csv  [0, 0, 1]\n",
            "4    /content/folder/test/3/3_28.csv  [0, 0, 1]\n",
            "..                               ...        ...\n",
            "297  /content/folder/test/2/2_96.csv  [0, 1, 0]\n",
            "298  /content/folder/test/2/2_99.csv  [0, 1, 0]\n",
            "299  /content/folder/test/2/2_56.csv  [0, 1, 0]\n",
            "300  /content/folder/test/2/2_61.csv  [0, 1, 0]\n",
            "301  /content/folder/test/2/2_39.csv  [0, 1, 0]\n",
            "\n",
            "[302 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define CustomDataset"
      ],
      "metadata": {
        "id": "EJJmsTvNAYOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, Data_frame):\n",
        "        self.train_path_list = Data_frame[\"train_path\"]\n",
        "        self.label_list = Data_frame[\"label\"]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        train_path = self.train_path_list[index]\n",
        "        df = pd.read_csv(train_path, usecols=[1], header=None)\n",
        "        a = np.array(df[1:201], dtype = np.float32)\n",
        "        b = np.transpose(a)\n",
        "        td = torch.tensor(b, dtype=torch.float)\n",
        "        td = F.interpolate(td.unsqueeze(0), size=(1024)).squeeze(0)\n",
        "        label_ = self.label_list[index]\n",
        "\n",
        "        tmp = {\"train_data\" : td  , \"labels\" : torch.tensor(label_)}\n",
        "\n",
        "        return tmp\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_path_list)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, Data_frame):\n",
        "        self.test_path_list = Data_frame[\"test_path\"]\n",
        "        self.label_list = Data_frame[\"label\"]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        test_path = self.test_path_list[index]\n",
        "        df = pd.read_csv(test_path, usecols=[1], header=None)\n",
        "        a = np.array(df[1:201], dtype = np.float32)\n",
        "        b = np.transpose(a)\n",
        "        td = torch.tensor(b, dtype=torch.float)\n",
        "        td = F.interpolate(td.unsqueeze(0), size=(1024)).squeeze(0)\n",
        "        label_ = self.label_list[index]\n",
        "\n",
        "        tmp = {\"test_data\" : td  , \"labels\" : torch.tensor(label_)}\n",
        "\n",
        "        return tmp\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.test_path_list)"
      ],
      "metadata": {
        "id": "qo3jCQfXLfFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataloader"
      ],
      "metadata": {
        "id": "8h7awb3Is_SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "train_dataset = CustomDataset(trainSet)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=1,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "test_dataset = TestDataset(testSet)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                          shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ([1,0,0], [0,1,0], [0,0,1])"
      ],
      "metadata": {
        "id": "48uFs29u_wKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainloader)) #train n(img)//batch_size\n",
        "print(len(testloader))  #test n(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJvd92zpEkrG",
        "outputId": "87d5f01b-5d9b-4395-9b61-7cbf0a3f6625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "tLWRMmsOSyqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # 첫 번째 합성곱 레이어\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        # 두 번째 합성곱 레이어\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        # 스킵 연결을 위한 합성곱 레이어 (stride가 1보다 클 때만 사용)\n",
        "        self.skip_layer = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 첫 번째 합성곱 레이어\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        # 두 번째 합성곱 레이어\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        # 스킵 연결\n",
        "        skip_out = self.skip_layer(x) if self.skip_layer is not None else x\n",
        "        out += skip_out\n",
        "\n",
        "        # ReLU 활성화 함수\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet1D(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes=3):\n",
        "        super(ResNet1D, self).__init__()\n",
        "\n",
        "        # 초기 합성곱 레이어\n",
        "        self.initial_conv = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.initial_bn = nn.BatchNorm1d(64)\n",
        "        self.initial_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Residual 블록\n",
        "        self.layer1 = self.make_layer(64, 64, stride=2)\n",
        "        self.layer2 = self.make_layer(64, 128, stride=2)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # 완전 연결 레이어\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, stride=1):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 초기 합성곱 레이어\n",
        "        x = self.initial_relu(self.initial_bn(self.initial_conv(x)))\n",
        "\n",
        "        # Residual 블록\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.global_avg_pooling(x)\n",
        "\n",
        "        # 완전 연결 레이어\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 모델 생성\n",
        "input_channels = 1  # 입력 데이터의 채널 수\n",
        "num_classes = 3  # 분류할 클래스 수\n",
        "model = ResNet1D(input_channels, num_classes)\n",
        "\n",
        "# 모델 확인\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHBq9CRyS5s6",
        "outputId": "14013880-4986-46d5-b17f-c22744b3fe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet1D(\n",
            "  (initial_conv): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
            "  (initial_bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (initial_relu): ReLU(inplace=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
            "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (skip_layer): Conv1d(64, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (skip_layer): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (skip_layer): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (skip_layer): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
            "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(model,(1,1024)).float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "kzfNXPdnnF7I",
        "outputId": "8372c47c-758b-4d54-8986-bde3b817e3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-81b5d93a2cf5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6dd52194d4e9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# 초기 합성곱 레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Residual 블록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet1D(1, 3)\n",
        "\n",
        "learning_rate=0.0001\n",
        "optimizer = Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "m = nn.Softmax(dim=1) #for resnet"
      ],
      "metadata": {
        "id": "Ha2lo6CLaTao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(4000):   # 데이터셋을 수차례 반복합니다.\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        tr , labels = data[\"train_data\"], data[\"labels\"]\n",
        "        tr = tr.to('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "        labels = labels.to('cuda:0' if torch.cuda.is_available() else \"cpu\").float()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # print(tr.size())\n",
        "        outputs = m(model(tr)).view(1,3).float()\n",
        "\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        output = loss(outputs,labels)\n",
        "        if i % 300 == 1:\n",
        "            print(\"Epoch\",epoch,\":\",output)\n",
        "\n",
        "        output.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ac9l4RLLawoP",
        "outputId": "9b51e918-2568-40f0-f457-b5f652ea0b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : tensor(0.5514, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 1 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 2 : tensor(0.5525, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 3 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 4 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 5 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 6 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 7 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 8 : tensor(0.5718, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 9 : tensor(0.5516, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 10 : tensor(0.5604, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 11 : tensor(0.5516, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 12 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 13 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 14 : tensor(0.5532, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 15 : tensor(0.5517, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 16 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 17 : tensor(0.5524, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 18 : tensor(0.5519, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 19 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 20 : tensor(0.5516, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 21 : tensor(0.5540, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 22 : tensor(0.5517, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 23 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 24 : tensor(0.5516, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 25 : tensor(0.5527, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 26 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 27 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 28 : tensor(0.5514, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 29 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 30 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 31 : tensor(0.5514, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 32 : tensor(0.5515, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 33 : tensor(0.5516, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "Epoch 34 : tensor(0.5519, device='cuda:0', grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-dfd09d517551>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# print(tr.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mdynamic_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mper_device_and_dtype_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero_grad_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tttt = []\n",
        "\n",
        "for i, data in enumerate(testloader, 0):\n",
        "      trr , labelss = data[\"test_data\"], data[\"labels\"]\n",
        "      trr = trr.to('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "      labelss = labelss.to('cuda:0' if torch.cuda.is_available() else \"cpu\").float()\n",
        "\n",
        "      outputss = m(model(trr)).view(1,3).float()\n",
        "      print(outputss)\n",
        "\n",
        "      tttt.append(torch.argmax(outputss,dim=1).item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9LiEu7vbqFi",
        "outputId": "91ec97f5-fd9d-4603-d992-a84818b79b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9855e-07, 9.0710e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.1280e-07, 2.7723e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.6284e-06, 1.8521e-04, 9.9981e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.9403e-07, 2.3654e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.5288e-07, 1.4655e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.8193e-04, 9.9826e-01, 1.2582e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.0119e-06, 1.7512e-03, 9.9825e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8056e-07, 1.3353e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.1598e-05, 5.9535e-03, 9.9402e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.1508e-06, 5.6733e-03, 9.9432e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1456e-07, 3.8992e-05, 9.9996e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.6483e-08, 2.1298e-06, 1.0000e+00]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.9178e-08, 1.7609e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0335e-06, 1.8081e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0348e-07, 5.8361e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.2002e-06, 1.9092e-02, 9.8091e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.6281e-05, 3.6407e-01, 6.3588e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.1825e-06, 1.9604e-02, 9.8039e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.6392e-08, 1.1890e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.0981e-05, 7.8785e-02, 9.2119e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.3979e-08, 7.8072e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.5632e-07, 1.8648e-04, 9.9981e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.5043e-07, 1.3542e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.7547e-07, 1.0175e-03, 9.9898e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.8897e-04, 1.1917e-03, 9.9842e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.3844e-06, 1.6034e-02, 9.8396e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.1633e-06, 4.4818e-02, 9.5518e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.0422e-06, 1.9866e-02, 9.8013e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.8847e-06, 9.8459e-01, 1.5400e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.8724e-08, 7.2225e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.5350e-08, 3.1925e-06, 1.0000e+00]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4394, 0.0439, 0.5167]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3390e-07, 3.5341e-05, 9.9996e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.6853e-05, 3.8322e-01, 6.1675e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.5867e-07, 1.2591e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.0437e-07, 1.0871e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.9481e-05, 4.8443e-02, 9.5152e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.6091e-05, 9.9530e-01, 4.6654e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9911e-08, 2.6091e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.2367e-07, 7.6511e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.6552e-07, 2.9709e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9231e-05, 2.1630e-03, 9.9774e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.8726e-07, 7.4094e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.5304e-06, 1.8430e-03, 9.9815e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.6222e-06, 1.0839e-02, 9.8916e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.2705e-06, 1.1386e-03, 9.9886e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.8832e-08, 1.0000e+00, 1.0515e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.0112e-05, 9.2500e-01, 7.4965e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4582e-07, 2.8166e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.3545e-07, 1.3916e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.1021e-07, 2.6062e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.4530e-07, 3.1573e-04, 9.9968e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.5961e-06, 9.9798e-01, 2.0198e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.0685e-07, 1.9872e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.8119e-06, 2.6270e-02, 9.7372e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.7136e-07, 1.1155e-04, 9.9989e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.3623e-04, 3.4963e-02, 9.6420e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3021e-05, 8.0957e-03, 9.9188e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.5559e-08, 1.1281e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.7861e-07, 9.9998e-01, 2.1093e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.7594e-06, 1.2806e-03, 9.9872e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.9620, 0.0026, 0.0354]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[7.5685e-06, 1.1506e-01, 8.8493e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.7615e-07, 9.8496e-05, 9.9990e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3477e-07, 1.5015e-04, 9.9985e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.8611e-08, 1.2893e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.0711e-07, 2.0073e-04, 9.9980e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.2842e-06, 3.0077e-04, 9.9969e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1992e-07, 1.3447e-05, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.1694e-06, 1.3666e-01, 8.6334e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.9675e-07, 3.4835e-06, 1.0000e+00]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.6163e-07, 6.4772e-05, 9.9993e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.9058e-07, 2.8990e-04, 9.9971e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.4976e-06, 1.9887e-02, 9.8011e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.2491e-05, 9.4286e-01, 5.7115e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.2526e-07, 4.6006e-05, 9.9995e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.5329e-07, 4.0677e-04, 9.9959e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.6247e-07, 2.8323e-04, 9.9972e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.9152e-06, 7.9738e-03, 9.9202e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.9835e-07, 1.0000e+00, 9.2873e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4484e-07, 2.1561e-05, 9.9998e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.8803e-06, 3.5906e-03, 9.9640e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.8895e-07, 3.7933e-05, 9.9996e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.7654e-07, 3.9093e-05, 9.9996e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.5851e-07, 8.2024e-05, 9.9992e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0695e-07, 2.4858e-05, 9.9997e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.2172e-07, 8.8167e-06, 9.9999e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.3054e-04, 6.2742e-01, 3.7225e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.1702e-05, 9.7566e-01, 2.4312e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0085, 0.9647, 0.0268]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[9.6622e-08, 4.2036e-06, 1.0000e+00]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.6359e-06, 9.1726e-01, 8.2733e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3989e-07, 4.5860e-05, 9.9995e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.0817e-07, 9.3106e-05, 9.9991e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3711e-07, 3.6275e-05, 9.9996e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3415e-07, 9.9598e-05, 9.9990e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.2229e-07, 3.8339e-03, 9.9617e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4856e-06, 7.9156e-04, 9.9921e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.6253e-06, 2.7610e-02, 9.7239e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1551e-05, 2.8796e-02, 9.7119e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.4831e-05, 5.0083e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9971e-01, 8.3860e-05, 2.0483e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.0478e-05, 4.4656e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9905e-01, 1.1828e-04, 8.2753e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9979e-01, 5.0475e-05, 1.6412e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9980e-01, 3.1945e-05, 1.7117e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9968e-01, 7.3300e-05, 2.4568e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 7.3505e-06, 2.1153e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9993e-01, 2.5092e-05, 4.6498e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 6.9278e-06, 4.0743e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 2.3245e-05, 2.8712e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9932e-01, 1.0003e-04, 5.8311e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9926e-01, 8.6266e-05, 6.5359e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9567e-01, 7.0496e-04, 3.6204e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9987e-01, 3.4077e-05, 9.6517e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9895e-01, 1.8446e-04, 8.6477e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9978e-01, 8.7488e-05, 1.3743e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9988e-01, 2.4438e-05, 9.2885e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.3161e-05, 4.2932e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0223, 0.0022, 0.9755]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9897e-01, 1.0375e-04, 9.2396e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9842e-01, 2.1863e-04, 1.3565e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9967e-01, 7.5671e-05, 2.4984e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9987e-01, 2.6614e-05, 1.0017e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9984e-01, 5.8259e-05, 9.9101e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9675e-01, 1.5125e-04, 3.1015e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9974e-01, 4.0029e-05, 2.1698e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9983e-01, 5.7047e-05, 1.1098e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5292, 0.0046, 0.4662]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9562e-01, 2.6824e-04, 4.1086e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9974e-01, 5.4956e-05, 2.0597e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9993e-01, 2.1356e-05, 4.9334e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 1.0100e-05, 6.5288e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 1.4471e-05, 1.9801e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9970e-01, 6.3097e-05, 2.3777e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9981e-01, 3.2529e-05, 1.5316e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9996e-01, 1.9288e-05, 1.6473e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9986e-01, 2.5260e-05, 1.1269e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9984e-01, 3.5527e-05, 1.2295e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 7.1631e-06, 5.0537e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9972e-01, 2.9280e-05, 2.5161e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9982e-01, 3.7536e-05, 1.4531e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9991e-01, 2.3656e-05, 6.9244e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9971e-01, 7.0564e-05, 2.2130e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9996e-01, 1.5837e-05, 2.4276e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 1.2000e-05, 7.1527e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9780e-01, 5.8393e-04, 1.6132e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9989e-01, 2.4414e-05, 8.4601e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9973e-01, 5.9775e-05, 2.1257e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9990e-01, 1.4529e-05, 8.8133e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9153e-01, 2.5263e-04, 8.2193e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9980e-01, 1.5443e-05, 1.8654e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.5176e-05, 4.8436e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 3.2393e-05, 4.6191e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9982e-01, 4.5332e-05, 1.3737e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9983e-01, 3.1093e-05, 1.3953e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9990e-01, 1.6501e-05, 8.4828e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 1.2056e-05, 2.0420e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9984e-01, 4.2404e-05, 1.1469e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9990e-01, 3.0009e-05, 6.7523e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9988e-01, 5.0072e-05, 7.0568e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 2.4390e-05, 5.5925e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 1.1818e-05, 4.2887e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9987e-01, 2.0563e-05, 1.1027e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9674e-01, 1.9711e-04, 3.0637e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9987e-01, 2.5860e-05, 1.0733e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9689e-01, 3.7846e-04, 2.7265e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9993e-01, 1.5713e-05, 4.9345e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.9471, 0.0017, 0.0512]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9984e-01, 6.9240e-05, 9.1777e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.3338e-05, 4.5027e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9998e-01, 4.3987e-06, 1.5908e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9998e-01, 5.4338e-06, 1.4598e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9982e-01, 5.1001e-05, 1.2574e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9969e-01, 4.6631e-05, 2.6313e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9983e-01, 5.1887e-05, 1.2151e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 6.5824e-06, 2.1006e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9987e-01, 1.6891e-05, 1.1117e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 9.8812e-06, 3.9751e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9963e-01, 4.9005e-05, 3.1920e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 6.7653e-06, 2.2843e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9991e-01, 1.8729e-05, 6.8799e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9996e-01, 1.4949e-05, 2.4343e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 7.2358e-06, 2.4642e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 5.9283e-06, 2.2580e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9931e-01, 6.3971e-05, 6.2208e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9947e-01, 5.6777e-05, 4.7560e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 1.1156e-05, 3.9333e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.2262e-05, 4.9735e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9994e-01, 1.9954e-05, 3.8238e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9957e-01, 1.0924e-04, 3.1646e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9967e-01, 6.1696e-05, 2.6859e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 2.6734e-05, 5.2842e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9993e-01, 3.2119e-05, 4.1194e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9965e-01, 6.1570e-05, 2.8891e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9997e-01, 7.6899e-06, 2.1367e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9992e-01, 1.4857e-05, 6.0310e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.9294e-02, 4.5036e-04, 9.2026e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9995e-01, 1.6003e-05, 3.4888e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9985e-01, 1.5229e-05, 1.3241e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9934e-01, 9.3328e-05, 5.6341e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.9990e-01, 1.3692e-05, 8.4974e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.2755e-06, 9.9997e-01, 3.1269e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0021, 0.4557, 0.5422]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[3.2003e-05, 9.9645e-01, 3.5200e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.9001e-05, 9.9966e-01, 2.9633e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.5441e-07, 9.9999e-01, 1.2194e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1400e-05, 9.9238e-01, 7.6080e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.1101e-06, 9.9978e-01, 2.1358e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.8190e-05, 9.9872e-01, 1.2435e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.2015e-06, 9.9993e-01, 6.9965e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0296e-05, 9.9688e-01, 3.1145e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3958e-06, 9.9997e-01, 3.0618e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.6135e-06, 9.9995e-01, 5.0102e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1061e-05, 9.9880e-01, 1.1882e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3762e-06, 9.9996e-01, 4.0191e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.4478e-05, 9.7376e-01, 2.6212e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3035e-05, 8.1020e-02, 9.1897e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.5122e-06, 9.9998e-01, 1.2415e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.2940e-06, 9.9999e-01, 3.2169e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0018, 0.0030, 0.9952]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[9.0173e-06, 9.9990e-01, 8.7756e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3320e-07, 1.0000e+00, 4.0946e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.2533e-05, 9.7238e-01, 2.7523e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.0490e-07, 9.9999e-01, 5.0253e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8211e-07, 1.0000e+00, 5.1622e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.1678e-05, 9.9842e-01, 1.5497e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3498e-04, 9.9915e-01, 6.1892e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.8988e-07, 1.0000e+00, 1.9451e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.8537e-05, 8.3258e-01, 1.6739e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.6478e-05, 9.9964e-01, 3.4056e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.0800e-06, 9.9982e-01, 1.7734e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0831e-05, 9.9977e-01, 2.2115e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.7746e-07, 1.0000e+00, 8.7383e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8607e-05, 9.9943e-01, 5.5544e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8869e-06, 9.9988e-01, 1.2190e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.8652e-07, 1.0000e+00, 2.8945e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.4190e-07, 9.9998e-01, 2.0566e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.3042e-06, 9.9306e-01, 6.9353e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.1127e-06, 9.9972e-01, 2.7600e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.4496e-05, 9.9483e-01, 5.1415e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1960e-06, 3.0523e-04, 9.9969e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4727e-06, 9.9987e-01, 1.3190e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.0896e-07, 1.0000e+00, 3.0764e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.9794e-06, 9.9861e-01, 1.3869e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.0719e-06, 9.9986e-01, 1.3597e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.7282e-07, 1.0000e+00, 3.5845e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.0383e-07, 1.0000e+00, 3.5481e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.6602e-06, 9.9986e-01, 1.3413e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[9.7936e-07, 9.9994e-01, 5.5314e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8285e-05, 9.9939e-01, 5.9575e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.3282e-05, 5.4310e-01, 4.5686e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.8510e-06, 9.9996e-01, 3.9773e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.7618e-07, 1.0000e+00, 3.4838e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.3773e-06, 9.9357e-01, 6.4178e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.3037e-06, 9.9992e-01, 7.0076e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.4259e-07, 7.4590e-04, 9.9925e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4019e-06, 1.0000e+00, 1.4447e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.7726e-05, 9.9581e-01, 4.1556e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.9921e-07, 9.9998e-01, 1.7115e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.4588e-07, 1.0000e+00, 2.0177e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.6542e-05, 9.9038e-01, 9.5997e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.7195e-05, 9.8297e-01, 1.7002e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.3705e-06, 9.9966e-01, 3.3287e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.5814e-05, 9.9705e-01, 2.9258e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.1479e-06, 9.9985e-01, 1.4019e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0740e-05, 9.9841e-01, 1.5755e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.6717e-05, 9.9299e-01, 6.9938e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.4494e-06, 9.9983e-01, 1.6702e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4895e-05, 9.9804e-01, 1.9476e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0047, 0.0089, 0.9864]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[1.4093e-06, 9.9999e-01, 9.1008e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0692e-05, 9.9971e-01, 2.8011e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.2070e-04, 5.4007e-01, 4.5971e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.3022e-05, 9.9830e-01, 1.6852e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.5492e-07, 9.9998e-01, 1.9208e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.1474e-05, 9.9946e-01, 5.1567e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1098e-06, 9.9985e-01, 1.5024e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.6395e-07, 1.0000e+00, 1.7412e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.1148e-07, 1.0000e+00, 4.7235e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.9021e-06, 9.9966e-01, 3.4252e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.4469e-07, 9.9999e-01, 6.0277e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.5076e-05, 9.9118e-01, 8.7643e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[5.1740e-06, 9.9976e-01, 2.3179e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.6938e-05, 9.9965e-01, 3.3552e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[3.6098e-07, 1.0000e+00, 5.7462e-07]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.6498e-07, 9.9995e-01, 4.5812e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[1.0978e-05, 9.4170e-01, 5.8289e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.7561e-07, 1.0000e+00, 2.3756e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.3185e-05, 9.7876e-01, 2.1214e-02]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[4.2363e-06, 9.9999e-01, 6.2791e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.1459e-06, 9.9446e-01, 5.5343e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.2988e-06, 4.7733e-02, 9.5226e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.8500e-06, 9.9889e-01, 1.1077e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[8.4064e-06, 9.9856e-01, 1.4365e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.9113e-06, 9.9919e-01, 8.0230e-04]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.5115e-05, 9.9871e-01, 1.2621e-03]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0240, 0.8187, 0.1572]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([[2.8837e-05, 4.6951e-01, 5.3046e-01]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[2.9716e-06, 9.9993e-01, 6.5960e-05]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[6.0142e-07, 1.0000e+00, 1.5144e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[7.5315e-07, 1.0000e+00, 1.8053e-06]], device='cuda:0',\n",
            "       grad_fn=<ViewBackward0>)\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.argmax(labelss,dim=1)-torch.argmax(outputss,dim=1)\n",
        "# print(A)\n",
        "print(torch.count_nonzero(A, dim=0))\n",
        "\n",
        "torch.argmax(outputss,dim=1)\n",
        "\n",
        "# torch.argmax(labelss,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ide57Ktgb82G",
        "outputId": "cbee4356-b42e-46f9-f433-4a323a8e3c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'best.pth')"
      ],
      "metadata": {
        "id": "W4gZBtyGg0Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tttt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEzcUYLrmDwo",
        "outputId": "17c3fd71-e6c3-4f88-892a-4b959a9ea667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
          ]
        }
      ]
    }
  ]
}